{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 52500 samples, validate on 17500 samples\n",
      "Epoch 1/10\n",
      "52500/52500 [==============================] - 77s 1ms/sample - loss: 1.0105 - acc: 0.7341 - val_loss: 0.6285 - val_acc: 0.7834\n",
      "Epoch 2/10\n",
      "52500/52500 [==============================] - 82s 2ms/sample - loss: 0.2680 - acc: 0.9205 - val_loss: 0.2281 - val_acc: 0.9322\n",
      "Epoch 3/10\n",
      "52500/52500 [==============================] - 81s 2ms/sample - loss: 0.1890 - acc: 0.9435 - val_loss: 0.2252 - val_acc: 0.9297\n",
      "Epoch 4/10\n",
      "52500/52500 [==============================] - 86s 2ms/sample - loss: 0.1504 - acc: 0.9558 - val_loss: 0.1448 - val_acc: 0.9577\n",
      "Epoch 5/10\n",
      "52500/52500 [==============================] - 89s 2ms/sample - loss: 0.1248 - acc: 0.9629 - val_loss: 0.1594 - val_acc: 0.9492\n",
      "Epoch 6/10\n",
      "52500/52500 [==============================] - 86s 2ms/sample - loss: 0.1076 - acc: 0.9676 - val_loss: 0.1118 - val_acc: 0.9676\n",
      "Epoch 7/10\n",
      "52500/52500 [==============================] - 85s 2ms/sample - loss: 0.0938 - acc: 0.9720 - val_loss: 0.2527 - val_acc: 0.9194\n",
      "Epoch 8/10\n",
      "52500/52500 [==============================] - 84s 2ms/sample - loss: 0.0847 - acc: 0.9748 - val_loss: 0.1800 - val_acc: 0.9378\n",
      "Epoch 9/10\n",
      "52500/52500 [==============================] - 93s 2ms/sample - loss: 0.0770 - acc: 0.9762 - val_loss: 0.1813 - val_acc: 0.9417\n",
      "Epoch 10/10\n",
      "52500/52500 [==============================] - 92s 2ms/sample - loss: 0.0706 - acc: 0.9782 - val_loss: 0.0773 - val_acc: 0.9759\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99      1708\n",
      "           1       0.98      0.99      0.98      1957\n",
      "           2       0.98      0.98      0.98      1804\n",
      "           3       0.97      0.98      0.97      1755\n",
      "           4       0.99      0.96      0.97      1675\n",
      "           5       0.98      0.97      0.98      1562\n",
      "           6       0.99      0.98      0.98      1748\n",
      "           7       0.98      0.98      0.98      1881\n",
      "           8       0.97      0.97      0.97      1726\n",
      "           9       0.94      0.97      0.96      1684\n",
      "\n",
      "    accuracy                           0.98     17500\n",
      "   macro avg       0.98      0.98      0.98     17500\n",
      "weighted avg       0.98      0.98      0.98     17500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import model\n",
    "from tensorflow.python.keras.callbacks import TensorBoard\n",
    "from tensorflow.python.keras.optimizers import SGD\n",
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.models import model_from_json\n",
    "import tensorflow as tf\n",
    "from time import time\n",
    "\n",
    "data = datasets.fetch_openml('mnist_784', version=1, return_X_y=True)\n",
    "\n",
    "dataset = data[0].reshape((data[0].shape[0], 28, 28, 1))\n",
    "labels = np.asanyarray(data[1])\n",
    "\n",
    "le = LabelBinarizer()\n",
    "le.fit(labels)\n",
    "labels = le.transform(labels)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    dataset/255.0, labels, test_size=0.25)\n",
    "\n",
    "model = model.LeNet.build((28, 28, 1))\n",
    "\n",
    "sgd = SGD(nesterov=True)\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(time()))\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=sgd, metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(X_train, Y_train, validation_data=(X_test, Y_test),\n",
    "              batch_size=128, epochs=10, verbose=1, callbacks=[tensorboard])\n",
    "\n",
    "predictions = model.predict(X_test, batch_size=128)\n",
    "print(classification_report(Y_test.argmax(axis=1),\n",
    "                            predictions.argmax(axis=1),\n",
    "                            target_names=[str(x) for x in le.classes_]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "model.save_weights(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52500, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
